{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit and Evaluate XGBoost Model (GridSearch Parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we want to fit an XGBoost Model only using the first time slice. \n",
    "\n",
    "In the first step of this experiement we want to find the best parameters that yield the best results using GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from matplotlib import pyplot as plt\n",
    "import monipy.utils.database as database\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Helping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prep_data(window=0, data_filter=4):\n",
    "    # load data\n",
    "    df = pd.concat([pd.read_csv(f\"data/useable_yes_unknown/filter_{data_filter}/sandor_full.csv\", index_col=[0]),\n",
    "              pd.read_csv(f\"data/useable_yes/filter_{data_filter}/ukt_full.csv\", index_col=[0]),\n",
    "              pd.read_csv(f\"data/useable_yes/filter_{data_filter}/freiburg_full.csv\", index_col=[0]),\n",
    "              pd.read_csv(f\"data/useable_yes/filter_{data_filter}/uka_corvolution_full.csv\", index_col=[0]),\n",
    "              pd.read_csv(f\"data/useable_yes/filter_{data_filter}/uka_klinik_full.csv\", index_col=[0]),\n",
    "             ])\n",
    "    \n",
    "    # rename column\n",
    "    df = df.rename(columns={\"window_Unnamed: 2093_level_1\": \"window\"})\n",
    "    \n",
    "    # filter for one starting window\n",
    "    df = df[df[\"window\"] == window]\n",
    "    \n",
    "    # get patient specific columns\n",
    "    df_patients_columns = database.get_all_patients().columns\n",
    "    \n",
    "    # drop patient specific columns and other columns\n",
    "    df = df.drop(columns = list(df_patients_columns))\n",
    "\n",
    "    columns = [\"seizure_id_Unnamed: 2091_level_1\", \n",
    "           \"record_id\", \"window\", \n",
    "           \"timestamp_start_Unnamed: 2094_level_1\"]\n",
    "    df = df.drop(columns=columns)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_val_split(df):\n",
    "    # split the data val, test, train\n",
    "    val_patients = pd.read_csv(\"data/patients/val_patients_1.csv\", index_col=[0]).reset_index(drop=True)\n",
    "    test_patients = pd.read_csv(\"data/patients/test_patients_1.csv\", index_col=[0]).reset_index(drop=True)\n",
    "    \n",
    "    df_val = df[df[\"patient_id\"].isin(val_patients.iloc[:, 0])].reset_index(drop=True)\n",
    "    df_test = df[df[\"patient_id\"].isin(test_patients.iloc[:, 0])].reset_index(drop=True)\n",
    "    df_train = df[~(df[\"patient_id\"].isin(set(val_patients.iloc[:, 0]) | set(test_patients.iloc[:, 0])))].reset_index(drop=True)\n",
    "    return df_val, df_test, df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(df_train, df_test, df_val, features, time_slice=0):\n",
    "    data_split = {}\n",
    "    for split in [\"val\", \"test\", \"train\"]:\n",
    "        data_split[f\"X_{split}\"] = eval(f\"df_{split}\")[[f\"{feature}_{time_slice}\" for feature in features]]\n",
    "        data_split[f\"y_{split}\"] = eval(f\"df_{split}\")[[\"seizure\"]]\n",
    "    return data_split[\"X_train\"], data_split[\"y_train\"], data_split[\"X_test\"], data_split[\"y_test\"], data_split[\"X_val\"], data_split[\"y_val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit xgboost model\n",
    "def fit_and_eval(X_train, y_train, X_test, y_test):\n",
    "    # Define initial hyperparameters\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',  # Binary classification objective\n",
    "        'learning_rate': 0.1, # 0.1  # Learning rate\n",
    "        'max_depth': 7,# 7 # Maximum depth of each tree\n",
    "        'n_estimators': 300,\n",
    "        'subsample': 0.8,  # Subsample ratio of the training instances\n",
    "        'colsample_bytree': 0.8,  # Subsample ratio of features when constructing each tree\n",
    "        'scale_pos_weight': 0.9, # 0.9\n",
    "    }\n",
    "\n",
    "    # Create the XGBoost classifier\n",
    "    model = XGBClassifier(**params)\n",
    "\n",
    "    # Train the XGBoost model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # return evaluation\n",
    "    return model, (accuracy_score(y_test, y_pred), confusion_matrix(y_test, y_pred), classification_report(y_test, y_pred),recall_score(y_test, y_pred),recall_score(y_test, y_pred, pos_label=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {'avg',\n",
    " 'csi',\n",
    " 'csi_filtered',\n",
    " 'csi_filtered_slope',\n",
    " 'csi_slope',\n",
    " 'csim',\n",
    " 'csim_filtered',\n",
    " 'csim_filtered_slope',\n",
    " 'csim_slope',\n",
    " 'cvi',\n",
    " 'hf',\n",
    " 'hr_diff',\n",
    " 'hr_diff_filtered',\n",
    " 'hr_diff_filtered_slope',\n",
    " 'hr_diff_slope',\n",
    " 'kurt',\n",
    " 'lf',\n",
    " 'lf_hf_ratio',\n",
    " 'mf_coef_center',\n",
    " 'mf_coef_left',\n",
    " 'mf_coef_right',\n",
    " 'mf_hurst_max',\n",
    " 'nnx',\n",
    " 'pnnx',\n",
    " 'quantile_25',\n",
    " 'quantile_50',\n",
    " 'quantile_75',\n",
    " 'rmssd',\n",
    " 'rmssd_dt',\n",
    " 'sd',\n",
    " 'sd1',\n",
    " 'sd2',\n",
    " 'skew',\n",
    " 'total_power',\n",
    " 'triangular_index',\n",
    " 'ulf',\n",
    " 'variance',\n",
    " 'vlf'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[creating new connection]\n",
      "(3320, 2092)\n"
     ]
    }
   ],
   "source": [
    "df = load_and_prep_data()\n",
    "print(df.shape)\n",
    "df_val, df_test, df_train = train_test_val_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params(X_train, y_train):\n",
    "    model = XGBClassifier()\n",
    "\n",
    "    # Define the hyperparameter grid for grid search\n",
    "    param_grid = {\n",
    "        'objective': ['binary:logistic'],\n",
    "        'n_estimators': [200, 300, 400],\n",
    "        'learning_rate': [0.5, 0.1, 0.01],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'scale_pos_weight':[0.1, 0.2, 0.9, 0.5],\n",
    "    }\n",
    "\n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "\n",
    "    # Fit the data to perform grid search\n",
    "    grid_search.fit(X_train, y_train)  # X_train and y_train are your training data\n",
    "\n",
    "    # Print the best hyperparameters and the corresponding score\n",
    "    print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "    print(\"Best Score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 200, 'objective': 'binary:logistic', 'scale_pos_weight': 0.2}\n",
      "Best Score:  0.9514792482104446\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, X_val, y_val = create_splits(df_train, df_test, df_val, features, 0)\n",
    "get_best_params(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fit and Evaluate XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, X_val, y_val = create_splits(df_train, df_test, df_val, features, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, (accuracy, cm, cr, recall_1, recall_0) = fit_and_eval(X_train, y_train , pd.concat([X_val, X_test]), pd.concat([y_val, y_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9293478260869565"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[713,   9],\n",
       "       [ 56, 142]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       722\n",
      "           1       0.94      0.72      0.81       198\n",
      "\n",
      "    accuracy                           0.93       920\n",
      "   macro avg       0.93      0.85      0.89       920\n",
      "weighted avg       0.93      0.93      0.93       920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# performance on test set\n",
    "display(accuracy)\n",
    "display(cm)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9343065693430657"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[293,   3],\n",
       "       [ 24,  91]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96       296\n",
      "           1       0.97      0.79      0.87       115\n",
      "\n",
      "    accuracy                           0.93       411\n",
      "   macro avg       0.95      0.89      0.91       411\n",
      "weighted avg       0.94      0.93      0.93       411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# performance on test set\n",
    "display(accuracy)\n",
    "display(cm)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, (accuracy, cm, cr, recall_1, recall_0) = fit_and_eval(pd.concat([X_train, X_test]), pd.concat([y_train, y_test]), X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9410609037328095"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[419,   7],\n",
       "       [ 23,  60]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       426\n",
      "           1       0.90      0.72      0.80        83\n",
      "\n",
      "    accuracy                           0.94       509\n",
      "   macro avg       0.92      0.85      0.88       509\n",
      "weighted avg       0.94      0.94      0.94       509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# performance on test set\n",
    "display(accuracy)\n",
    "display(cm)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[2148    0]\n",
      " [   0  252]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2148\n",
      "           1       1.00      1.00      1.00       252\n",
      "\n",
      "    accuracy                           1.00      2400\n",
      "   macro avg       1.00      1.00      1.00      2400\n",
      "weighted avg       1.00      1.00      1.00      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# performance on train set\n",
    "y_pred_train = model.predict(X_train)\n",
    "print(accuracy_score(y_train, y_pred_train))\n",
    "print(confusion_matrix(y_train, y_pred_train))\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [pipenv: uni]",
   "language": "python",
   "name": "uni"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
