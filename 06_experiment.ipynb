{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit and Evaluate XGBoost Model for different data filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we want to fit an XGBoost Model using different datasets on which we have applied different data filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from matplotlib import pyplot as plt\n",
    "import monipy.utils.database as database\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Helping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prep_data(window=0, data_filter=4):\n",
    "    # load data\n",
    "    df = pd.concat([pd.read_csv(f\"data/useable_yes/filter_{data_filter}/sandor_full.csv\", index_col=[0]),\n",
    "              pd.read_csv(f\"data/useable_yes/filter_{data_filter}/ukt_full.csv\", index_col=[0]),\n",
    "              pd.read_csv(f\"data/useable_yes/filter_{data_filter}/freiburg_full.csv\", index_col=[0]),\n",
    "              pd.read_csv(f\"data/useable_yes/filter_{data_filter}/uka_corvolution_full.csv\", index_col=[0]),\n",
    "              pd.read_csv(f\"data/useable_yes/filter_{data_filter}/uka_klinik_full.csv\", index_col=[0]),\n",
    "             ])\n",
    "    \n",
    "    # rename column\n",
    "    df = df.rename(columns={\"window_Unnamed: 2093_level_1\": \"window\"})\n",
    "    \n",
    "    # filter for one starting window\n",
    "    df = df[df[\"window\"] == window]\n",
    "    \n",
    "    # get patient specific columns\n",
    "    df_patients_columns = database.get_all_patients().columns\n",
    "    \n",
    "    # drop patient specific columns and other columns\n",
    "    df = df.drop(columns = list(df_patients_columns))\n",
    "\n",
    "    columns = [\"seizure_id_Unnamed: 2091_level_1\", \n",
    "           \"record_id\", \"window\", \n",
    "           \"timestamp_start_Unnamed: 2094_level_1\"]\n",
    "    df = df.drop(columns=columns)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_val_split(df):\n",
    "    # split the data val, test, train\n",
    "    val_patients = pd.read_csv(\"data/patients/val_patients_1.csv\", index_col=[0]).reset_index(drop=True)\n",
    "    test_patients = pd.read_csv(\"data/patients/test_patients_1.csv\", index_col=[0]).reset_index(drop=True)\n",
    "    \n",
    "    df_val = df[df[\"patient_id\"].isin(val_patients.iloc[:, 0])].reset_index(drop=True)\n",
    "    df_test = df[df[\"patient_id\"].isin(test_patients.iloc[:, 0])].reset_index(drop=True)\n",
    "    df_train = df[~(df[\"patient_id\"].isin(set(val_patients.iloc[:, 0]) | set(test_patients.iloc[:, 0])))].reset_index(drop=True)\n",
    "    return df_val, df_test, df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(df_train, df_test, df_val, features, time_slice=0):\n",
    "    data_split = {}\n",
    "    for split in [\"val\", \"test\", \"train\"]:\n",
    "        data_split[f\"X_{split}\"] = eval(f\"df_{split}\")[[f\"{feature}_{time_slice}\" for feature in features]]\n",
    "        data_split[f\"y_{split}\"] = eval(f\"df_{split}\")[[\"seizure\"]]\n",
    "    return data_split[\"X_train\"], data_split[\"y_train\"], data_split[\"X_test\"], data_split[\"y_test\"], data_split[\"X_val\"], data_split[\"y_val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit xgboost model\n",
    "def fit_and_eval(X_train, y_train, X_test, y_test):\n",
    "    # Define initial hyperparameters\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',  # Binary classification objective\n",
    "        'learning_rate': 0.1,  # Learning rate\n",
    "        'max_depth': 7, # Maximum depth of each tree\n",
    "        'n_estimators': 300,\n",
    "        'subsample': 0.8,  # Subsample ratio of the training instances\n",
    "        'colsample_bytree': 0.8,  # Subsample ratio of features when constructing each tree\n",
    "        'scale_pos_weight': 0.9,\n",
    "    }\n",
    "\n",
    "    # Create the XGBoost classifier\n",
    "    model = XGBClassifier(**params)\n",
    "\n",
    "    # Train the XGBoost model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # return evaluation\n",
    "    return model, (accuracy_score(y_test, y_pred), confusion_matrix(y_test, y_pred), classification_report(y_test, y_pred),recall_score(y_test, y_pred),recall_score(y_test, y_pred, pos_label=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {'avg',\n",
    " 'csi',\n",
    " 'csi_filtered',\n",
    " 'csi_filtered_slope',\n",
    " 'csi_slope',\n",
    " 'csim',\n",
    " 'csim_filtered',\n",
    " 'csim_filtered_slope',\n",
    " 'csim_slope',\n",
    " 'cvi',\n",
    " 'hf',\n",
    " 'hr_diff',\n",
    " 'hr_diff_filtered',\n",
    " 'hr_diff_filtered_slope',\n",
    " 'hr_diff_slope',\n",
    " 'kurt',\n",
    " 'lf',\n",
    " 'lf_hf_ratio',\n",
    " 'mf_coef_center',\n",
    " 'mf_coef_left',\n",
    " 'mf_coef_right',\n",
    " 'mf_hurst_max',\n",
    " 'nnx',\n",
    " 'pnnx',\n",
    " 'quantile_25',\n",
    " 'quantile_50',\n",
    " 'quantile_75',\n",
    " 'rmssd',\n",
    " 'rmssd_dt',\n",
    " 'sd',\n",
    " 'sd1',\n",
    " 'sd2',\n",
    " 'skew',\n",
    " 'total_power',\n",
    " 'triangular_index',\n",
    " 'ulf',\n",
    " 'variance',\n",
    " 'vlf'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[creating new connection]\n",
      "(3195, 2092)\n"
     ]
    }
   ],
   "source": [
    "df = load_and_prep_data()\n",
    "print(df.shape)\n",
    "df_val, df_test, df_train = train_test_val_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test model performance for different data filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84ce3b78-7062-43b0-8281-9c3cb67bfd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[creating new connection]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Columns (2105) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "Columns (2105) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[creating new connection]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Columns (2105) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "Columns (2105) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[creating new connection]\n",
      "[creating new connection]\n"
     ]
    }
   ],
   "source": [
    "performance = []\n",
    "for i in range(1,5,1):\n",
    "    df = load_and_prep_data(data_filter=i)\n",
    "    df_val, df_test, df_train = train_test_val_split(df)\n",
    "    X_train, y_train, X_test, y_test, X_val, y_val = create_splits(df_train, df_test, df_val, features, 0)\n",
    "    model, (accuracy, cm, cr, recall_1, recall_0) = fit_and_eval(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    performance.append({\n",
    "        \"filter\": i,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"recall_1\": recall_1,\n",
    "        \"recall_0\": recall_0,\n",
    "        \"cm\": cm,\n",
    "        \"cr\": cr,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d37daf7-9b3d-426f-acd9-bf3d632885f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance = pd.DataFrame(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d45805e6-b176-4bb1-b252-9ce0f644f627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filter</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>cm</th>\n",
       "      <th>cr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.958124</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>[[516, 4], [21, 56]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.919105</td>\n",
       "      <td>0.568421</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>[[480, 6], [41, 54]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.935433</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>[[540, 10], [31, 54]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.945274</td>\n",
       "      <td>0.817391</td>\n",
       "      <td>0.996516</td>\n",
       "      <td>[[286, 1], [21, 94]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   filter  accuracy  recall_1  recall_0                     cm   \n",
       "0       1  0.958124  0.727273  0.992308   [[516, 4], [21, 56]]  \\\n",
       "1       2  0.919105  0.568421  0.987654   [[480, 6], [41, 54]]   \n",
       "2       3  0.935433  0.635294  0.981818  [[540, 10], [31, 54]]   \n",
       "3       4  0.945274  0.817391  0.996516   [[286, 1], [21, 94]]   \n",
       "\n",
       "                                                  cr  \n",
       "0                precision    recall  f1-score   ...  \n",
       "1                precision    recall  f1-score   ...  \n",
       "2                precision    recall  f1-score   ...  \n",
       "3                precision    recall  f1-score   ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a42f610-c485-449e-9545-a228d9be1eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       520\n",
      "           1       0.93      0.73      0.82        77\n",
      "\n",
      "    accuracy                           0.96       597\n",
      "   macro avg       0.95      0.86      0.90       597\n",
      "weighted avg       0.96      0.96      0.96       597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_performance.loc[0, \"cr\"]) # filter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93f65340-666f-47c7-a0e2-f719ae773f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       287\n",
      "           1       0.99      0.82      0.90       115\n",
      "\n",
      "    accuracy                           0.95       402\n",
      "   macro avg       0.96      0.91      0.93       402\n",
      "weighted avg       0.95      0.95      0.94       402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_performance.loc[3, \"cr\"]) # filter 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [pipenv: uni]",
   "language": "python",
   "name": "uni"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
