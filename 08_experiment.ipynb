{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Fit XGBoost model and evaluate on healthy dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we want to fit an XGBoost Model on data which only consists of recordings of epilepsy patients and then evaluate the model performance on a data set which only consists of recordings of healthy people in their daily life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from matplotlib import pyplot as plt\n",
    "import monipy.utils.database as database\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Helping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prep_data(window=0, data_filter=4):\n",
    "    # load data\n",
    "    df = pd.concat([pd.read_csv(f\"data/useable_yes_unknown/filter_{data_filter}/sandor_full.csv\", index_col=[0]),\n",
    "              pd.read_csv(f\"data/useable_yes/filter_{data_filter}/ukt_full.csv\", index_col=[0]),\n",
    "              pd.read_csv(f\"data/useable_yes/filter_{data_filter}/freiburg_full.csv\", index_col=[0]),\n",
    "              pd.read_csv(f\"data/useable_yes/filter_{data_filter}/uka_corvolution_full.csv\", index_col=[0]),\n",
    "              pd.read_csv(f\"data/useable_yes/filter_{data_filter}/uka_klinik_full.csv\", index_col=[0]),\n",
    "             ])\n",
    "    \n",
    "    # rename column\n",
    "    df = df.rename(columns={\"window_Unnamed: 2093_level_1\": \"window\"})\n",
    "    \n",
    "    # filter for one starting window\n",
    "    df = df[df[\"window\"] == window]\n",
    "    \n",
    "    # get patient specific columns\n",
    "    df_patients_columns = database.get_all_patients().columns\n",
    "    \n",
    "    # drop patient specific columns and other columns\n",
    "    df = df.drop(columns = list(df_patients_columns))\n",
    "\n",
    "    columns = [\"seizure_id_Unnamed: 2091_level_1\", \n",
    "           \"record_id\", \"window\", \n",
    "           \"timestamp_start_Unnamed: 2094_level_1\"]\n",
    "    df = df.drop(columns=columns)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_val_split(df):\n",
    "    # split the data val, test, train\n",
    "    val_patients = pd.read_csv(\"data/patients/val_patients_1.csv\", index_col=[0]).reset_index(drop=True)\n",
    "    test_patients = pd.read_csv(\"data/patients/test_patients_1.csv\", index_col=[0]).reset_index(drop=True)\n",
    "    \n",
    "    df_val = df[df[\"patient_id\"].isin(val_patients.iloc[:, 0])].reset_index(drop=True)\n",
    "    df_test = df[df[\"patient_id\"].isin(test_patients.iloc[:, 0])].reset_index(drop=True)\n",
    "    df_train = df[~(df[\"patient_id\"].isin(set(val_patients.iloc[:, 0]) | set(test_patients.iloc[:, 0])))].reset_index(drop=True)\n",
    "    return df_val, df_test, df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(df_train, df_test, df_val, features, time_slice=0):\n",
    "    data_split = {}\n",
    "    for split in [\"val\", \"test\", \"train\"]:\n",
    "        data_split[f\"X_{split}\"] = eval(f\"df_{split}\")[[f\"{feature}_{time_slice}\" for feature in features]]\n",
    "        data_split[f\"y_{split}\"] = eval(f\"df_{split}\")[[\"seizure\"]]\n",
    "    return data_split[\"X_train\"], data_split[\"y_train\"], data_split[\"X_test\"], data_split[\"y_test\"], data_split[\"X_val\"], data_split[\"y_val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit xgboost model\n",
    "def fit_and_eval(X_train, y_train, X_test, y_test):\n",
    "    # Define initial hyperparameters\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',  # Binary classification objective\n",
    "        'learning_rate': 0.1,  # Learning rate\n",
    "        'max_depth': 7, # Maximum depth of each tree\n",
    "        'n_estimators': 300,\n",
    "        'subsample': 0.8,  # Subsample ratio of the training instances\n",
    "        'colsample_bytree': 0.8,  # Subsample ratio of features when constructing each tree\n",
    "        'scale_pos_weight': 0.9,\n",
    "    }\n",
    "\n",
    "    # Create the XGBoost classifier\n",
    "    model = XGBClassifier(**params)\n",
    "\n",
    "    # Train the XGBoost model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # return evaluation\n",
    "    return model, (accuracy_score(y_test, y_pred), confusion_matrix(y_test, y_pred), classification_report(y_test, y_pred),recall_score(y_test, y_pred),recall_score(y_test, y_pred, pos_label=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {'avg',\n",
    " 'csi',\n",
    " 'csi_filtered',\n",
    " 'csi_filtered_slope',\n",
    " 'csi_slope',\n",
    " 'csim',\n",
    " 'csim_filtered',\n",
    " 'csim_filtered_slope',\n",
    " 'csim_slope',\n",
    " 'cvi',\n",
    " 'hf',\n",
    " 'hr_diff',\n",
    " 'hr_diff_filtered',\n",
    " 'hr_diff_filtered_slope',\n",
    " 'hr_diff_slope',\n",
    " 'kurt',\n",
    " 'lf',\n",
    " 'lf_hf_ratio',\n",
    " 'mf_coef_center',\n",
    " 'mf_coef_left',\n",
    " 'mf_coef_right',\n",
    " 'mf_hurst_max',\n",
    " 'nnx',\n",
    " 'pnnx',\n",
    " 'quantile_25',\n",
    " 'quantile_50',\n",
    " 'quantile_75',\n",
    " 'rmssd',\n",
    " 'rmssd_dt',\n",
    " 'sd',\n",
    " 'sd1',\n",
    " 'sd2',\n",
    " 'skew',\n",
    " 'total_power',\n",
    " 'triangular_index',\n",
    " 'ulf',\n",
    " 'variance',\n",
    " 'vlf'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[creating new connection]\n",
      "(2106, 2092)\n"
     ]
    }
   ],
   "source": [
    "df = load_and_prep_data()\n",
    "print(df.shape)\n",
    "df_val, df_test, df_train = train_test_val_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fit and Evaluate XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for i in range(0,5,1):\n",
    "    x = x + [f\"{feature}_{i}\" for feature in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[x]\n",
    "y_train = df_train.seizure\n",
    "\n",
    "X_test = df_test[x]\n",
    "y_test = df_test.seizure\n",
    "\n",
    "X_val = df_val[x]\n",
    "y_val = df_val.seizure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, (accuracy, cm, cr, recall_1, recall_0) = fit_and_eval(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9673202614379085"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[266,   3],\n",
       "       [  7,  30]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       269\n",
      "           1       0.91      0.81      0.86        37\n",
      "\n",
      "    accuracy                           0.97       306\n",
      "   macro avg       0.94      0.90      0.92       306\n",
      "weighted avg       0.97      0.97      0.97       306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# performance on test set\n",
    "display(accuracy)\n",
    "display(cm)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, (accuracy, cm, cr, recall_1, recall_0) = fit_and_eval(X_train, y_train, pd.concat([X_test, X_val]), pd.concat([y_test, y_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.937592867756315"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[528,   9],\n",
       "       [ 33, 103]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       537\n",
      "           1       0.92      0.76      0.83       136\n",
      "\n",
      "    accuracy                           0.94       673\n",
      "   macro avg       0.93      0.87      0.90       673\n",
      "weighted avg       0.94      0.94      0.94       673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# performance on test set\n",
    "display(accuracy)\n",
    "display(cm)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, (accuracy, cm, cr, recall_1, recall_0) = fit_and_eval( pd.concat([X_train, X_test, X_val]),  pd.concat([y_train, y_test, y_val]), pd.concat([X_test, X_val]), pd.concat([y_test, y_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# read data\n",
    "df_alltag_corvolution = pd.read_csv(f\"data/useable_yes/alltag/alltag_corvolution_regular_data.csv\", index_col=[0], header=[0,1])\n",
    "df_alltag_movisens = pd.read_csv(f\"data/useable_yes/alltag/alltag_movisens_regular_data.csv\", index_col=[0], header=[0,1])\n",
    "\n",
    "\n",
    "df = pd.concat([df_alltag_corvolution, df_alltag_movisens])\n",
    "df.columns = df.columns.map(\"_\".join)\n",
    "\n",
    "# rename column\n",
    "df = df.rename(columns={\"record_id_Unnamed: 2092_level_1\": \"record_id\"})\n",
    "\n",
    "# add label column\n",
    "df[\"seizure\"] = 0\n",
    "\n",
    "# rename column\n",
    "df = df.rename(columns={\"window_Unnamed: 2093_level_1\": \"window\"})\n",
    "\n",
    "\n",
    "columns = [\"seizure_id_Unnamed: 2091_level_1\", \n",
    "        \"record_id\", \"window\", \n",
    "        \"timestamp_start_Unnamed: 2094_level_1\"]\n",
    "df = df.drop(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[x]\n",
    "y = df[\"seizure\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948\n",
      "[[1896  104]\n",
      " [   0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97      2000\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.50      0.47      0.49      2000\n",
      "weighted avg       1.00      0.95      0.97      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# return evaluation\n",
    "print(accuracy_score(y, y_pred))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "print(classification_report(y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
