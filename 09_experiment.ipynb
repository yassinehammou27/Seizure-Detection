{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit and Evaluate XGBoost Model for different data splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we want to fit an XGBoost Model using different data splits. In the previous experiments we split the data by patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from matplotlib import pyplot as plt\n",
    "import monipy.utils.database as database\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Helping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prep_data(window=0, data_filter=4):\n",
    "    # load data\n",
    "    df = pd.concat([pd.read_csv(f\"data/useable_yes_unknown/filter_{data_filter}/sandor_full.csv\", index_col=[0]),\n",
    "              pd.read_csv(f\"data/useable_yes/filter_{data_filter}/ukt_full.csv\", index_col=[0]),\n",
    "              pd.read_csv(f\"data/useable_yes/filter_{data_filter}/freiburg_full.csv\", index_col=[0]),\n",
    "              pd.read_csv(f\"data/useable_yes/filter_{data_filter}/uka_corvolution_full.csv\", index_col=[0]),\n",
    "              pd.read_csv(f\"data/useable_yes/filter_{data_filter}/uka_klinik_full.csv\", index_col=[0]),\n",
    "             ])\n",
    "    \n",
    "    # rename column\n",
    "    df = df.rename(columns={\"window_Unnamed: 2093_level_1\": \"window\"})\n",
    "    \n",
    "    # filter for one starting window\n",
    "    df = df[df[\"window\"] == window]\n",
    "    \n",
    "    # get patient specific columns\n",
    "    df_patients_columns = database.get_all_patients().columns\n",
    "    \n",
    "    # drop patient specific columns and other columns\n",
    "    df = df.drop(columns = list(df_patients_columns))\n",
    "\n",
    "    columns = [\"seizure_id_Unnamed: 2091_level_1\",  \"window\", \n",
    "           \"timestamp_start_Unnamed: 2094_level_1\"]\n",
    "    df = df.drop(columns=columns)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_val_split(df):\n",
    "    # split the data val, test, train\n",
    "    val_patients = pd.read_csv(\"data/patients/val_patients_1.csv\", index_col=[0]).reset_index(drop=True)\n",
    "    test_patients = pd.read_csv(\"data/patients/test_patients_1.csv\", index_col=[0]).reset_index(drop=True)\n",
    "    \n",
    "    df_val = df[df[\"patient_id\"].isin(val_patients.iloc[:, 0])].reset_index(drop=True)\n",
    "    df_test = df[df[\"patient_id\"].isin(test_patients.iloc[:, 0])].reset_index(drop=True)\n",
    "    df_train = df[~(df[\"patient_id\"].isin(set(val_patients.iloc[:, 0]) | set(test_patients.iloc[:, 0])))].reset_index(drop=True)\n",
    "    return df_val, df_test, df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(df_train, df_test, features, time_slice=0):\n",
    "    data_split = {}\n",
    "    for split in [\"test\", \"train\"]:\n",
    "        data_split[f\"X_{split}\"] = eval(f\"df_{split}\")[[f\"{feature}_{time_slice}\" for feature in features]]\n",
    "        data_split[f\"y_{split}\"] = eval(f\"df_{split}\")[[\"seizure\"]]\n",
    "    return data_split[\"X_train\"], data_split[\"y_train\"], data_split[\"X_test\"], data_split[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit xgboost model\n",
    "def fit_and_eval(X_train, y_train, X_test, y_test):\n",
    "    # Define initial hyperparameters\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',  # Binary classification objective\n",
    "        'learning_rate': 0.1,  # Learning rate\n",
    "        'max_depth': 3, # Maximum depth of each tree\n",
    "        'n_estimators': 400,\n",
    "        'subsample': 0.8,  # Subsample ratio of the training instances\n",
    "        'colsample_bytree': 0.8,  # Subsample ratio of features when constructing each tree\n",
    "        'scale_pos_weight': 0.5,\n",
    "    }\n",
    "\n",
    "    # Create the XGBoost classifier\n",
    "    model = XGBClassifier(**params)\n",
    "\n",
    "    # Train the XGBoost model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # return evaluation\n",
    "    return model, (accuracy_score(y_test, y_pred), confusion_matrix(y_test, y_pred), classification_report(y_test, y_pred),recall_score(y_test, y_pred),recall_score(y_test, y_pred, pos_label=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit with custom params\n",
    "def fit(X_train, y_train, X_test, y_test, params):\n",
    "    # Create the XGBoost classifier\n",
    "    model = XGBClassifier(**params)\n",
    "\n",
    "    # Train the XGBoost model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # return evaluation\n",
    "    return model, (accuracy_score(y_test, y_pred), confusion_matrix(y_test, y_pred), classification_report(y_test, y_pred),recall_score(y_test, y_pred),recall_score(y_test, y_pred, pos_label=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {'avg',\n",
    " 'csi',\n",
    " 'csi_filtered',\n",
    " 'csi_filtered_slope',\n",
    " 'csi_slope',\n",
    " 'csim',\n",
    " 'csim_filtered',\n",
    " 'csim_filtered_slope',\n",
    " 'csim_slope',\n",
    " 'cvi',\n",
    " 'hf',\n",
    " 'hr_diff',\n",
    " 'hr_diff_filtered',\n",
    " 'hr_diff_filtered_slope',\n",
    " 'hr_diff_slope',\n",
    " 'kurt',\n",
    " 'lf',\n",
    " 'lf_hf_ratio',\n",
    " 'mf_coef_center',\n",
    " 'mf_coef_left',\n",
    " 'mf_coef_right',\n",
    " 'mf_hurst_max',\n",
    " 'nnx',\n",
    " 'pnnx',\n",
    " 'quantile_25',\n",
    " 'quantile_50',\n",
    " 'quantile_75',\n",
    " 'rmssd',\n",
    " 'rmssd_dt',\n",
    " 'sd',\n",
    " 'sd1',\n",
    " 'sd2',\n",
    " 'skew',\n",
    " 'total_power',\n",
    " 'triangular_index',\n",
    " 'ulf',\n",
    " 'variance',\n",
    " 'vlf'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_columns = [\n",
    "    'id',\n",
    "    'local_patient_id',\n",
    "    'recording_center',\n",
    "    'name',\n",
    "    'firstname',\n",
    "    'birthday',\n",
    "    'sex',\n",
    "    'weight',\n",
    "    'height',\n",
    "    'comment',\n",
    "    'do_ignore',\n",
    "    'use_for_training',\n",
    "    'epilepsy_onset'\n",
    " ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[creating new connection]\n"
     ]
    }
   ],
   "source": [
    "df = load_and_prep_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Splitting by Record_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_records = pd.read_csv(\"data/test_records_1.csv\", index_col=[0])\n",
    "test_records_list = list(test_records[\"0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        True\n",
       "3        True\n",
       "5       False\n",
       "7       False\n",
       "9       False\n",
       "        ...  \n",
       "1465     True\n",
       "1467     True\n",
       "1469     True\n",
       "1471     True\n",
       "1473     True\n",
       "Name: record_id, Length: 3320, dtype: bool"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.record_id.isin(test_records_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[df.record_id.isin(test_records_list)]\n",
    "df_train = df[~df.record_id.isin(test_records_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(592, 2093)\n",
      "(2728, 2093)\n"
     ]
    }
   ],
   "source": [
    "print(df_test.shape)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = create_splits(df_train, df_test, features, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params(X_train, y_train):\n",
    "    model = XGBClassifier()\n",
    "\n",
    "    # Define the hyperparameter grid for grid search\n",
    "    param_grid = {\n",
    "        'objective': ['binary:logistic'],\n",
    "        'n_estimators': [200, 300, 400],\n",
    "        'learning_rate': [0.5, 0.1, 0.01],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'scale_pos_weight':[0.1, 0.2, 0.9, 0.5],\n",
    "    }\n",
    "\n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "\n",
    "    # Fit the data to perform grid search\n",
    "    grid_search.fit(X_train, y_train)  # X_train and y_train are your training data\n",
    "\n",
    "    # Print the best hyperparameters and the corresponding score\n",
    "    print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "    print(\"Best Score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300, 'objective': 'binary:logistic', 'scale_pos_weight': 0.1}\n",
      "Best Score:  0.9574861881792575\n"
     ]
    }
   ],
   "source": [
    "get_best_params(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Fit and Evaluate XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, (accuracy, cm, cr, recall_1, recall_0) = fit_and_eval(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8868243243243243"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[480,  12],\n",
       "       [ 55,  45]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.93       492\n",
      "           1       0.79      0.45      0.57       100\n",
      "\n",
      "    accuracy                           0.89       592\n",
      "   macro avg       0.84      0.71      0.75       592\n",
      "weighted avg       0.88      0.89      0.87       592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# performance on test set\n",
    "display(accuracy)\n",
    "display(cm)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8868243243243243"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[480,  12],\n",
       "       [ 55,  45]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.93       492\n",
      "           1       0.79      0.45      0.57       100\n",
      "\n",
      "    accuracy                           0.89       592\n",
      "   macro avg       0.84      0.71      0.75       592\n",
      "weighted avg       0.88      0.89      0.87       592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# performance on test set\n",
    "display(accuracy)\n",
    "display(cm)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Splitting by recording center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[creating new connection]\n"
     ]
    }
   ],
   "source": [
    "df_sandor = pd.read_csv(f\"data/useable_yes/filter_4/sandor_full.csv\", index_col=[0])\n",
    "df_ukt_movisens = pd.read_csv(f\"data/useable_yes/filter_4/ukt_full.csv\", index_col=[0])\n",
    "df_freiburg = pd.read_csv(f\"data/useable_yes/filter_4/freiburg_full.csv\", index_col=[0])\n",
    "df_uka_corvolution = pd.read_csv(f\"data/useable_yes/filter_4/uka_corvolution_full.csv\", index_col=[0])\n",
    "df_uka_klinik = pd.read_csv(f\"data/useable_yes/filter_4/uka_klinik_full.csv\", index_col=[0])\n",
    "      \n",
    "\n",
    "# rename column\n",
    "df_sandor = df_sandor.rename(columns={\"window_Unnamed: 2093_level_1\": \"window\"})\n",
    "df_ukt_movisens = df_ukt_movisens.rename(columns={\"window_Unnamed: 2093_level_1\": \"window\"})\n",
    "df_freiburg = df_freiburg.rename(columns={\"window_Unnamed: 2093_level_1\": \"window\"})\n",
    "df_uka_corvolution = df_uka_corvolution.rename(columns={\"window_Unnamed: 2093_level_1\": \"window\"})\n",
    "df_uka_klinik = df_uka_klinik.rename(columns={\"window_Unnamed: 2093_level_1\": \"window\"})\n",
    "\n",
    "# filter for one starting window\n",
    "df_sandor = df_sandor[df_sandor[\"window\"] == 0]\n",
    "df_ukt_movisens = df_ukt_movisens[df_ukt_movisens[\"window\"] == 0]\n",
    "df_freiburg = df_freiburg[df_freiburg[\"window\"] == 0]\n",
    "df_uka_corvolution = df_uka_corvolution[df_uka_corvolution[\"window\"] == 0]\n",
    "df_uka_klinik = df_uka_klinik[df_uka_klinik[\"window\"] == 0]\n",
    "\n",
    "# get patient specific columns\n",
    "df_patients_columns = database.get_all_patients().columns\n",
    "\n",
    "# drop patient specific columns and other columns\n",
    "df_sandor = df_sandor.drop(columns = list(df_patients_columns))\n",
    "df_ukt_movisens = df_ukt_movisens.drop(columns = list(df_patients_columns))\n",
    "df_freiburg = df_freiburg.drop(columns = list(df_patients_columns))\n",
    "df_uka_corvolution = df_uka_corvolution.drop(columns = list(df_patients_columns))\n",
    "df_uka_klinik = df_uka_klinik.drop(columns = list(df_patients_columns))\n",
    "\n",
    "columns = [\"seizure_id_Unnamed: 2091_level_1\",  \"window\", \n",
    "        \"timestamp_start_Unnamed: 2094_level_1\"]\n",
    "df_sandor = df_sandor.drop(columns=columns)\n",
    "df_ukt_movisens = df_ukt_movisens.drop(columns=columns)\n",
    "df_freiburg = df_freiburg.drop(columns=columns)\n",
    "df_uka_corvolution = df_uka_corvolution.drop(columns=columns)\n",
    "df_uka_klinik = df_uka_klinik.drop(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sandor = df_sandor[[f\"{feature}_0\" for feature in features]]\n",
    "X_ukt_movisens = df_ukt_movisens[[f\"{feature}_0\" for feature in features]]\n",
    "X_freiburg = df_freiburg[[f\"{feature}_0\" for feature in features]]\n",
    "X_uka_corvolution = df_uka_corvolution[[f\"{feature}_0\" for feature in features]]\n",
    "X_uka_klinik = df_uka_klinik[[f\"{feature}_0\" for feature in features]]\n",
    "\n",
    "y_sandor = df_sandor[\"seizure\"]\n",
    "y_ukt_movisens = df_ukt_movisens[\"seizure\"]\n",
    "y_freiburg = df_freiburg[\"seizure\"]\n",
    "y_uka_corvolution = df_uka_corvolution[\"seizure\"]\n",
    "y_uka_klinik = df_uka_klinik[\"seizure\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 38)\n",
      "(450, 38)\n",
      "(1506, 38)\n",
      "(352, 38)\n",
      "(737, 38)\n"
     ]
    }
   ],
   "source": [
    "print(X_sandor.shape)\n",
    "print(X_ukt_movisens.shape)\n",
    "print(X_freiburg.shape)\n",
    "print(X_uka_corvolution.shape)\n",
    "print(X_uka_klinik.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9133333333333333\n",
      "[[490  10]\n",
      " [ 42  58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       500\n",
      "           1       0.85      0.58      0.69       100\n",
      "\n",
      "    accuracy                           0.91       600\n",
      "   macro avg       0.89      0.78      0.82       600\n",
      "weighted avg       0.91      0.91      0.91       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, (accuracy, cm, cr, recall_1, recall_0) = fit_and_eval(X_freiburg, y_freiburg, pd.concat([X_sandor, X_ukt_movisens]), pd.concat([y_sandor, y_ukt_movisens]))\n",
    "\n",
    "print(accuracy)\n",
    "print(cm)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9190821256038647\n",
      "[[1328   52]\n",
      " [  82  194]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      1380\n",
      "           1       0.79      0.70      0.74       276\n",
      "\n",
      "    accuracy                           0.92      1656\n",
      "   macro avg       0.87      0.83      0.85      1656\n",
      "weighted avg       0.92      0.92      0.92      1656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, (accuracy, cm, cr, recall_1, recall_0) = fit_and_eval(X_ukt_movisens, y_ukt_movisens, pd.concat([X_sandor, X_freiburg]), pd.concat([y_sandor, y_freiburg]))\n",
    "\n",
    "print(accuracy)\n",
    "print(cm)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9161554192229039\n",
      "[[1588   42]\n",
      " [ 122  204]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      1630\n",
      "           1       0.83      0.63      0.71       326\n",
      "\n",
      "    accuracy                           0.92      1956\n",
      "   macro avg       0.88      0.80      0.83      1956\n",
      "weighted avg       0.91      0.92      0.91      1956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, (accuracy, cm, cr, recall_1, recall_0) = fit_and_eval(X_sandor, y_sandor, pd.concat([X_ukt_movisens, X_freiburg]), pd.concat([y_ukt_movisens, y_freiburg]))\n",
    "\n",
    "print(accuracy)\n",
    "print(cm)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9175697865353037\n",
      "[[2547   73]\n",
      " [ 178  247]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      2620\n",
      "           1       0.77      0.58      0.66       425\n",
      "\n",
      "    accuracy                           0.92      3045\n",
      "   macro avg       0.85      0.78      0.81      3045\n",
      "weighted avg       0.91      0.92      0.91      3045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, (accuracy, cm, cr, recall_1, recall_0) = fit_and_eval(X_sandor, y_sandor, pd.concat([X_ukt_movisens, X_freiburg, X_uka_klinik, X_uka_corvolution]), pd.concat([y_ukt_movisens, y_freiburg, y_uka_klinik, y_uka_corvolution]))\n",
    "\n",
    "print(accuracy)\n",
    "print(cm)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9231329690346084\n",
      "[[2287   83]\n",
      " [ 128  247]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      2370\n",
      "           1       0.75      0.66      0.70       375\n",
      "\n",
      "    accuracy                           0.92      2745\n",
      "   macro avg       0.85      0.81      0.83      2745\n",
      "weighted avg       0.92      0.92      0.92      2745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, (accuracy, cm, cr, recall_1, recall_0) = fit_and_eval(X_ukt_movisens, y_ukt_movisens, pd.concat([X_sandor, X_freiburg, X_uka_klinik, X_uka_corvolution]), pd.concat([y_sandor, y_freiburg, y_uka_klinik, y_uka_corvolution]))\n",
    "\n",
    "print(accuracy)\n",
    "print(cm)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9277679100059206\n",
      "[[1457   33]\n",
      " [  89  110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      1490\n",
      "           1       0.77      0.55      0.64       199\n",
      "\n",
      "    accuracy                           0.93      1689\n",
      "   macro avg       0.86      0.77      0.80      1689\n",
      "weighted avg       0.92      0.93      0.92      1689\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, (accuracy, cm, cr, recall_1, recall_0) = fit_and_eval(X_freiburg, y_freiburg, pd.concat([X_ukt_movisens, X_sandor, X_uka_klinik, X_uka_corvolution]), pd.concat([y_ukt_movisens, y_sandor, y_uka_klinik, y_uka_corvolution]))\n",
    "\n",
    "print(accuracy)\n",
    "print(cm)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9083570750237417\n",
      "[[1706   49]\n",
      " [ 144  207]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95      1755\n",
      "           1       0.81      0.59      0.68       351\n",
      "\n",
      "    accuracy                           0.91      2106\n",
      "   macro avg       0.87      0.78      0.81      2106\n",
      "weighted avg       0.90      0.91      0.90      2106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, (accuracy, cm, cr, recall_1, recall_0) = fit_and_eval(pd.concat([X_uka_corvolution, X_uka_klinik]), pd.concat([y_uka_corvolution, y_uka_klinik]), pd.concat([X_ukt_movisens, X_freiburg, X_sandor]), pd.concat([y_ukt_movisens, y_freiburg, y_sandor]))\n",
    "\n",
    "print(accuracy)\n",
    "print(cm)\n",
    "print(cr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [pipenv: uni]",
   "language": "python",
   "name": "uni"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
