{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit and Evaluate XGBoost Model to achieve best possibel performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we want to bring all the knowledge that we gained in the previous experiments together to fit a model and achieve the best possible performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.inspection import permutation_importance, PartialDependenceDisplay\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Helping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_val_split(df):\n",
    "    # split the data val, test, train\n",
    "    val_patients = pd.read_csv(\"data/patients/val_patients_1.csv\", index_col=[0]).reset_index(drop=True)\n",
    "    test_patients = pd.read_csv(\"data/patients/test_patients_1.csv\", index_col=[0]).reset_index(drop=True)\n",
    "    \n",
    "    df_val = df[df[\"patient_id\"].isin(val_patients.iloc[:, 0])].reset_index(drop=True)\n",
    "    df_test = df[df[\"patient_id\"].isin(test_patients.iloc[:, 0])].reset_index(drop=True)\n",
    "    df_train = df[~(df[\"patient_id\"].isin(set(val_patients.iloc[:, 0]) | set(test_patients.iloc[:, 0])))].reset_index(drop=True)\n",
    "    return df_val, df_test, df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(df_train, df_test, df_val, features, patient_features=[], time_slice=0):\n",
    "    data_split = {}\n",
    "    for split in [\"val\", \"test\", \"train\"]:\n",
    "        \n",
    "        data_split[f\"X_{split}\"] = eval(f\"df_{split}\")[[f\"{feature}_{time_slice}\" for feature in features] + patient_features]\n",
    "        data_split[f\"y_{split}\"] = eval(f\"df_{split}\")[[\"seizure\"]]\n",
    "    return data_split[\"X_train\"], data_split[\"y_train\"], data_split[\"X_test\"], data_split[\"y_test\"], data_split[\"X_val\"], data_split[\"y_val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params(X_train, y_train):\n",
    "    model = XGBClassifier()\n",
    "\n",
    "    # Define the hyperparameter grid for grid search\n",
    "    param_grid = {\n",
    "        'objective': ['binary:logistic'],\n",
    "        'n_estimators': [200, 300, 400],\n",
    "        'learning_rate': [0.5, 0.1, 0.01],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'scale_pos_weight':[0.1, 0.2, 0.9, 0.5],\n",
    "    }\n",
    "\n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "\n",
    "    # Fit the data to perform grid search\n",
    "    grid_search.fit(X_train, y_train)  # X_train and y_train are your training data\n",
    "\n",
    "    # Print the best hyperparameters and the corresponding score\n",
    "    print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "    print(\"Best Score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit xgboost model\n",
    "def fit_and_eval(X_train, y_train, X_test, y_test):\n",
    "    # Define initial hyperparameters\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',  # Binary classification objective\n",
    "        'learning_rate': 0.1,  # Learning rate\n",
    "        'max_depth': 7, # Maximum depth of each tree\n",
    "        'n_estimators': 300,\n",
    "        #'subsample': 0.8,  # Subsample ratio of the training instances\n",
    "        'colsample_bytree': 0.8,  # Subsample ratio of features when constructing each tree\n",
    "        'scale_pos_weight': 0.9,\n",
    "    }\n",
    "\n",
    "    # Create the XGBoost classifier\n",
    "    model = XGBClassifier(**params)\n",
    "\n",
    "    # Train the XGBoost model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # return evaluation\n",
    "    return model, (accuracy_score(y_test, y_pred), confusion_matrix(y_test, y_pred), classification_report(y_test, y_pred),recall_score(y_test, y_pred),recall_score(y_test, y_pred, pos_label=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_threshold(model, X_test, threshold):\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    prediction = pd.DataFrame(y_pred_proba)\n",
    "    prediction[\"label\"] = prediction.apply(lambda x: 1 if x[1] >= threshold else 0, axis=1)\n",
    "\n",
    "    return prediction.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {'avg',\n",
    " 'csi',\n",
    " 'csi_filtered',\n",
    " 'csi_filtered_slope',\n",
    " 'csi_slope',\n",
    " 'csim',\n",
    " 'csim_filtered',\n",
    " 'csim_filtered_slope',\n",
    " 'csim_slope',\n",
    " 'cvi',\n",
    " 'hf',\n",
    " 'hr_diff',\n",
    " 'hr_diff_filtered',\n",
    " 'hr_diff_filtered_slope',\n",
    " 'hr_diff_slope',\n",
    " 'kurt',\n",
    " 'lf',\n",
    " 'lf_hf_ratio',\n",
    " 'mf_coef_center',\n",
    " 'mf_coef_left',\n",
    " 'mf_coef_right',\n",
    " 'mf_hurst_max',\n",
    " 'nnx',\n",
    " 'pnnx',\n",
    " 'quantile_25',\n",
    " 'quantile_50',\n",
    " 'quantile_75',\n",
    " 'rmssd',\n",
    " 'rmssd_dt',\n",
    " 'sd',\n",
    " 'sd1',\n",
    " 'sd2',\n",
    " 'skew',\n",
    " 'total_power',\n",
    " 'triangular_index',\n",
    " 'ulf',\n",
    " 'variance',\n",
    " 'vlf'\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modelling using patient data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Using Age and Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Columns (2097,2099,2100,2105) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"prep_patient_data.csv\", index_col=[0])\n",
    "\n",
    "# filter out birthday of \"1900-01-01\"\n",
    "df = df[~(df[\"birthday\"] == \"1900-01-01\")]\n",
    "\n",
    "# rename column\n",
    "df = df.rename(columns={\"window_Unnamed: 2093_level_1\": \"window\"})\n",
    "    \n",
    "# filter for a starting window of zero\n",
    "df = df[df[\"window\"] == -18]\n",
    "\n",
    "# get dummy variables for sex\n",
    "df = pd.concat([pd.get_dummies(df.sex), df], axis=1).drop(columns=\"sex\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test val split (only considere first timeslice)\n",
    "df_val, df_test, df_train = train_test_val_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for i in range(14,29,1):\n",
    "    x = x + [f\"{feature}_{i}\" for feature in features]\n",
    "\n",
    "x += [\"age\", \"f\", \"m\", \"u\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[x]\n",
    "y_train = df_train.seizure\n",
    "\n",
    "X_test = df_test[x]\n",
    "y_test = df_test.seizure\n",
    "\n",
    "X_val = df_val[x]\n",
    "y_val = df_val.seizure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best model parameters\n",
    "#get_best_params(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seizure\n",
       "0    287\n",
       "1    115\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model, (accuracy, cm, cr, recall_1, recall_0) = fit_and_eval(X_train, y_train, pd.concat([X_test, X_val]), pd.concat([y_test, y_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[637,   4],\n",
       "       [ 49, 145]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       641\n",
      "           1       0.97      0.75      0.85       194\n",
      "\n",
      "    accuracy                           0.94       835\n",
      "   macro avg       0.95      0.87      0.90       835\n",
      "weighted avg       0.94      0.94      0.93       835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Try a different prediction threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = predict_with_threshold(model, pd.concat([X_test, X_val]), 0.007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[599,  42],\n",
       "       [ 12, 182]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(pd.concat([y_test, y_val]), y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96       641\n",
      "           1       0.81      0.94      0.87       194\n",
      "\n",
      "    accuracy                           0.94       835\n",
      "   macro avg       0.90      0.94      0.91       835\n",
      "weighted avg       0.94      0.94      0.94       835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pd.concat([y_test, y_val]), y_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Agerange instead of age as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Columns (2097,2099,2100,2105) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"prep_patient_data.csv\", index_col=[0])\n",
    "\n",
    "# filter out birthday of \"1900-01-01\"\n",
    "df = df[~(df[\"birthday\"] == \"1900-01-01\")]\n",
    "\n",
    "# rename column\n",
    "df = df.rename(columns={\"window_Unnamed: 2093_level_1\": \"window\"})\n",
    "    \n",
    "# filter for a starting window of zero\n",
    "df = df[df[\"window\"] == -18]\n",
    "    \n",
    "age_ranges = list(range(0, 101, 5))\n",
    "\n",
    "df['agerange'] = pd.cut(df.age, age_ranges,labels=False, include_lowest = True)\n",
    "# get dummy variables for sex\n",
    "df = pd.concat([pd.get_dummies(df.sex), df], axis=1).drop(columns=\"sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for i in range(14,29,1):\n",
    "    x = x + [f\"{feature}_{i}\" for feature in features]\n",
    "\n",
    "x += [\"age\", \"f\", \"m\", \"u\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[x]\n",
    "y_train = df_train.seizure\n",
    "\n",
    "X_test = df_test[x]\n",
    "y_test = df_test.seizure\n",
    "\n",
    "X_val = df_val[x]\n",
    "y_val = df_val.seizure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model, (accuracy, cm, cr, recall_1, recall_0) = fit_and_eval(X_train, y_train, pd.concat([X_test, X_val]), pd.concat([y_test, y_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[637,   4],\n",
       "       [ 49, 145]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       641\n",
      "           1       0.97      0.75      0.85       194\n",
      "\n",
      "    accuracy                           0.94       835\n",
      "   macro avg       0.95      0.87      0.90       835\n",
      "weighted avg       0.94      0.94      0.93       835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Try a different prediction threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = predict_with_threshold(model, pd.concat([X_test, X_val]), 0.007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[599,  42],\n",
       "       [ 12, 182]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(pd.concat([y_test, y_val]), y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96       641\n",
      "           1       0.81      0.94      0.87       194\n",
      "\n",
      "    accuracy                           0.94       835\n",
      "   macro avg       0.90      0.94      0.91       835\n",
      "weighted avg       0.94      0.94      0.94       835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pd.concat([y_test, y_val]), y_pred_2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [pipenv: uni]",
   "language": "python",
   "name": "uni"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
